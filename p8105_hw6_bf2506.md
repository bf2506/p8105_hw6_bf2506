p8105_hw6_bf2506
================
bf2506
2022-11-30

``` r
library(tidyverse)
library(modelr)
```

### Problem 2

``` r
homi_data = 
  read.csv("./data/homicide-data.csv") %>%
  janitor::clean_names()
```

Create a city_state variable, and a binary resolved variable of
disposition. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO –
these don’t report victim race. Also omit Tulsa, AL – this is a data
entry mistake. For this problem, limit your analysis those for whom
victim_race is white or black. Be sure that victim_age is numeric.

``` r
homi_data = 
  homi_data %>% 
  mutate(city_state = paste(city, state, sep = ", ", collapse = NULL)) %>% 
  mutate(resolved = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age)) %>%
  relocate(city_state) %>% 
  filter( !(city_state %in% c("Dallas, TX", "Phoenix, AZ", " Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("Black", "White")) %>% 
  mutate(
    victim_race = as.factor(victim_race),
    victim_sex = as.factor(victim_sex))
```

    ## Warning in mask$eval_all_mutate(quo): 强制改变过程中产生了NA

For the city of Baltimore, MD, use the glm function to fit a logistic
regression with resolved vs unresolved as the outcome and victim age,
sex and race as predictors. Save the output of glm as an R object.

``` r
baltimore_df =
  homi_data %>%
  filter(city_state == "Baltimore, MD")

fit_logistic_balt = 
  glm(resolved ~ victim_age + victim_sex + victim_race, family = binomial(), data = baltimore_df) 
```

Apply the broom::tidy to this object; and obtain the estimate and
confidence interval of the adjusted odds ratio for solving homicides
comparing male victims to female victims keeping all other variables
fixed.

``` r
fit_balt_table = fit_logistic_balt %>% broom::tidy() 

sexMale_balt = 
  fit_balt_table %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    OR = exp(estimate),
    conf_lower = exp(estimate - 1.96*std.error),
    conf_upper = exp(estimate + 1.96*std.error))

sexMale_balt
```

    ## # A tibble: 1 × 8
    ##   term           estimate std.error statistic  p.value    OR conf_lower conf_u…¹
    ##   <chr>             <dbl>     <dbl>     <dbl>    <dbl> <dbl>      <dbl>    <dbl>
    ## 1 victim_sexMale   -0.854     0.138     -6.18 6.26e-10 0.426      0.325    0.558
    ## # … with abbreviated variable name ¹​conf_upper

- The estimate value of the adjusted odds ratio is 0.4255117
- The corresponding 95% confidence interval is (0.324559, 0.5578655)

Run glm for each of the cities in your dataset, and extract the adjusted
odds ratio (and CI) for solving homicides comparing male victims to
female victims.

``` r
func = function(everycity_df) {
  
  fit_everycity = 
    glm(resolved ~ victim_age + victim_sex + victim_race, family = binomial(), data = everycity_df) %>%
    broom::tidy() %>% 
    mutate(
    OR = exp(estimate),
    conf_lower = exp(estimate - 1.96*std.error),
    conf_upper = exp(estimate + 1.96*std.error)) %>%
    filter(term == "victim_sexMale") %>%
    select(OR, conf_lower, conf_upper)
  
  return(fit_everycity)
}
```

``` r
everycity_df = 
  homi_data %>%
  nest(data = uid:resolved) %>%
  mutate(
    outputs = map(data, func)) %>%
  select(-data) %>%
  unnest(outputs)

everycity_df %>%
  knitr::kable(digits = 3)
```

| city_state         |    OR | conf_lower | conf_upper |
|:-------------------|------:|-----------:|-----------:|
| Albuquerque, NM    | 1.767 |      0.831 |      3.761 |
| Atlanta, GA        | 1.000 |      0.684 |      1.463 |
| Baltimore, MD      | 0.426 |      0.325 |      0.558 |
| Baton Rouge, LA    | 0.381 |      0.209 |      0.695 |
| Birmingham, AL     | 0.870 |      0.574 |      1.318 |
| Boston, MA         | 0.674 |      0.356 |      1.276 |
| Buffalo, NY        | 0.521 |      0.290 |      0.935 |
| Charlotte, NC      | 0.884 |      0.557 |      1.403 |
| Chicago, IL        | 0.410 |      0.336 |      0.501 |
| Cincinnati, OH     | 0.400 |      0.236 |      0.677 |
| Columbus, OH       | 0.532 |      0.378 |      0.750 |
| Denver, CO         | 0.479 |      0.236 |      0.971 |
| Detroit, MI        | 0.582 |      0.462 |      0.734 |
| Durham, NC         | 0.812 |      0.392 |      1.683 |
| Fort Worth, TX     | 0.669 |      0.397 |      1.127 |
| Fresno, CA         | 1.335 |      0.580 |      3.071 |
| Houston, TX        | 0.711 |      0.558 |      0.907 |
| Indianapolis, IN   | 0.919 |      0.679 |      1.242 |
| Jacksonville, FL   | 0.720 |      0.537 |      0.966 |
| Las Vegas, NV      | 0.837 |      0.608 |      1.154 |
| Long Beach, CA     | 0.410 |      0.156 |      1.082 |
| Los Angeles, CA    | 0.662 |      0.458 |      0.956 |
| Louisville, KY     | 0.491 |      0.305 |      0.790 |
| Memphis, TN        | 0.723 |      0.529 |      0.988 |
| Miami, FL          | 0.515 |      0.304 |      0.872 |
| Milwaukee, wI      | 0.727 |      0.499 |      1.060 |
| Minneapolis, MN    | 0.947 |      0.478 |      1.875 |
| Nashville, TN      | 1.034 |      0.685 |      1.562 |
| New Orleans, LA    | 0.585 |      0.422 |      0.811 |
| New York, NY       | 0.262 |      0.138 |      0.499 |
| Oakland, CA        | 0.563 |      0.365 |      0.868 |
| Oklahoma City, OK  | 0.974 |      0.624 |      1.520 |
| Omaha, NE          | 0.382 |      0.203 |      0.721 |
| Philadelphia, PA   | 0.496 |      0.378 |      0.652 |
| Pittsburgh, PA     | 0.431 |      0.265 |      0.700 |
| Richmond, VA       | 1.006 |      0.498 |      2.033 |
| San Antonio, TX    | 0.705 |      0.398 |      1.249 |
| Sacramento, CA     | 0.669 |      0.335 |      1.337 |
| Savannah, GA       | 0.867 |      0.422 |      1.780 |
| San Bernardino, CA | 0.500 |      0.171 |      1.462 |
| San Diego, CA      | 0.413 |      0.200 |      0.855 |
| San Francisco, CA  | 0.608 |      0.317 |      1.165 |
| St. Louis, MO      | 0.703 |      0.530 |      0.932 |
| Stockton, CA       | 1.352 |      0.621 |      2.942 |
| Tampa, FL          | 0.808 |      0.348 |      1.876 |
| Tulsa, OK          | 0.976 |      0.614 |      1.552 |
| Washington, DC     | 0.690 |      0.468 |      1.017 |
